{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef6498c",
   "metadata": {},
   "source": [
    "# Classification Template\n",
    "Supervised learning classification technique. It is used to predict a qualitative outcome.  \n",
    "(i.e. *yes* or *no*, *convert* or *not convert*, *positive* or *negative*, in this case  `good` or `bad` etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6b53a",
   "metadata": {},
   "source": [
    "## Import Libraries and Data\n",
    "-  Import Libraries  \n",
    "-  Import dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pycaret.classification import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "data = pd.read_csv('./data/GermanCredit.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dfa032",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "-  dataframe shape  \n",
    "-  identify null / na values  \n",
    "-  Tukey Five Number - describe() \n",
    "-  Seaborn Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30605ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shape\n",
    "print(f'The data has {data.shape[0]} records and {data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb61461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nulls in the data\n",
    "msk = data.isna().sum()\n",
    "msk[msk > 0] # or\n",
    "#msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4916e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about numeric features\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inforamtion about the category data\n",
    "data.describe(include='object').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27224e",
   "metadata": {},
   "source": [
    "### Data visualization with Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x= data['credit']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y= data['purpose']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= data['credit_amt'], kde=True, color='brown');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['age'], color='pink');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['duration_mnth'], color='orange');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1260d07",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Create unseen data\n",
    "- Set up data \n",
    "- Create model\n",
    "- tune model (if required)\n",
    "- Finalize model\n",
    "- plot model\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512eae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding out Data as unseen from the model\n",
    "unseen = data.sample(n= 100)\n",
    "data = data[~data.index.isin(unseen.index)]\n",
    "print(f'Data for model: {data.shape},\\nData for unseen predictions: {unseen.shape}')\n",
    "unseen.to_csv('./data/Germancredit_unseen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e2144",
   "metadata": {},
   "source": [
    "#### Setting up with Pycaret 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2044fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setup(data = data, target = 'credit', train_size=0.9, fix_imbalance=True, session_id=2930,\n",
    "          ordinal_features = {'checking_acc': [ 'none','Less than 0 DM','Btw 0 to 199 DM','Equal or Greater than 200 DM'],\n",
    "                            'savings_acc':['none','Less than 100 DM','Btw 100 to 499 DM','Btw 500 to 999 DM','Equal or Greater than 1000 DM'],\n",
    "                             'emp_status':['unemployed','Less than a year','Btw 1 to 4 years','Btw 4 to 7 years', 'Greater than 7 years']\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the transformed data\n",
    "s.dataset_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39ae6a",
   "metadata": {},
   "source": [
    "#### Creating model\n",
    "> The models used on the data by owner can be found at [UCI website](https://archive-beta.ics.uci.edu/dataset/144/statlog+german+credit+data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bb9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## comparing the eight models - i always add lightgbm\n",
    "compare_models(include=['xgboost', 'rf', 'lr', 'catboost', 'lightgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e737c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Creating light GBM model\n",
    "lgbm = create_model('lightgbm')\n",
    "tuned_lgbm = tune_model(lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Creating Cat Boost Classifier model\n",
    "cb = create_model('catboost')\n",
    "tuned_cb = tune_model(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfe2a4",
   "metadata": {},
   "source": [
    "#### Plotting Model - catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_lgbm, plot = 'confusion_matrix') #'auc' , 'error', 'pr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cb, plot = 'auc') #'auc' , 'error', 'pr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc879cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cb, plot = 'pr') #'auc' , 'error', 'pr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b3524",
   "metadata": {},
   "source": [
    "#### Plotting Model - Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cef7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lgbm, plot = 'confusion_matrix') #'auc' , 'error', 'pr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lgbm, plot = 'auc') #'auc' , 'error', 'pr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lgbm, plot = 'feature') #'auc' , 'error', 'pr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702c91e",
   "metadata": {},
   "source": [
    "### Predicting on Test Data - Using LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data - LGBM\n",
    "predict_model(lgbm, raw_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO predict the whole data - lgbm\n",
    "predict_model(lgbm, data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c491e",
   "metadata": {},
   "source": [
    "### Testing Model on the Unseen data\n",
    "- The real test of a model depends on how well it perform on an unseen data. Not only measured, accuracy but the Precison, Recall and F1_score as they are highly important for the business model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f65f91",
   "metadata": {},
   "source": [
    "#### Predicting on Unseen data using Light GBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf329ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict the unseen data\n",
    "lgbm_pred = predict_model(lgbm, data = unseen)\n",
    "\n",
    "# Uncomment and RUn to view where it got the credit wrong\n",
    "# pred[pred['credit'] != pred['prediction_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36edd9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a confusion Matrix\n",
    "y_true = lgbm_pred['credit']\n",
    "y_pred = lgbm_pred['prediction_label']\n",
    "lgbm_cm =confusion_matrix(y_true, y_pred)\n",
    "lgbm_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_cm_df = pd.DataFrame(lgbm_cm, index = ['bad', 'good'], columns = ['bad', 'good'])\n",
    "lgbm_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b59374",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data = lgbm_cm_df, annot=True, fmt = '00');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (lgbm_cm_df['good']['good'] + lgbm_cm_df['bad']['bad']) / sum(sum(i) for i in lgbm_cm_df.values)\n",
    "print(f'LGBM model Accuracy: {accuracy * 100:.1f}%')\n",
    "\n",
    "# Calculate precision\n",
    "precision = lgbm_cm_df['good']['good'] / (lgbm_cm_df['good']['good'] + lgbm_cm_df['bad']['good'])\n",
    "print(f'LGBM model Precision: {precision * 100:.1f}%')\n",
    "\n",
    "# Calculate recall\n",
    "recall = lgbm_cm_df['good']['good'] / (lgbm_cm_df['good']['good'] + lgbm_cm_df['good']['bad'])\n",
    "print(f'LGBM model Recall: {recall * 100:.1f}%')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(f'LGBM model F1 Score: {f1_score * 100:.1f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
